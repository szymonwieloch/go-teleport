# Protocol design

## Protocol format

While JSON remains the most popular format for exchanging messages in the modern Internet, it is not without issues. 
It is relatively slow, requires manual forward and backward compatibility management,
requires manual writing of parsers and encoders in all languages that need to use it and requires maintenance of documentation.
Those problems can be solved by introducing a binary protocol with a schema that generates code for parsing and encoding messages.

The most popular binary message format at the moment is Google [Protobuf](https://developers.google.com/protocol-buffers). 
It is commonly used together with the [gRPC](https://grpc.io/) protocol and is an efficient replacement for REST API.

## Communication design

There are five operations that the client may perform:

- Start a job.
- Stop the job.
- Check the job status.
- Stream logs of the job (stderr and stdout).
- List pending jobs.

Those five operations can be directly mapped to five API methods:

- **Start** - starts the job. Returns one of:
  - Started task information (for example job ID that is necessary for other API calls)
  - Error in case the could could not be started.
- **Stop** - stops the given job. Returns finished process information.
- **GetStatus** - obtains information about the given job. Returns one of:
  - Finished process information
  - Running process information.
- **Logs** - stream of strings representing pieces of stdout or stderr. Once the client connects it first receives cached output of the given job, then a live stream generated by the process. This means that the output of the given task will be stored in the server in RAM.
- **List** - lists all pending tasks.

The precise message and API specification can be found [here](../proto/teleport.proto).

# Authentication And Authorization

Since this is a toy project, the default working mode is unencrypted and unauthenticated to allow easy exploration of the project.
Safe mode is optional and requires providing extra certificates. In real production solutions it's usually the opposite - safety is provided by default.

To enable safety it is required to:
1. Encrypt the connection using TLS.
2. Authenticate the user.
3. Authorize the given operation that user wants to perform.

Other safety features such as hardening dockers are out of scope for this project.

Production-ready solution would normally consist of an authorization service that upon authentication would issue signed documents with user privileges valid for some period of time,
that in turn would be sent by the user and used by the server to limit the scope of allowed operations.
The communication looks roughly like this:

1. Client connects to the authorization service.
2. Bidirectional encryption is established using TLS. Domain of the server is verified using certificate.
3. Client proves his identity using a certificate or password.
5. Authorization service check in the database what permissions are assigned to the client.
6. Authorization service generates a secret signed token and sends it to the client through the encrypted channel (the key is secret)
  Token is usually a document (i.e. JSON) that describes assigned privileges. 
  By signing it becomes a proof that the authorization service allows access to specific resources for some period of time to the owner of this token.
7. Having the token client can perform requests to all services until the certificate expires.
8. Client connects to the given microservice, in our case to the teleport server. Server Identity is again verified using TLS. Channels becomes encrypted.
9. Client certificate is optional - depending on the implementation client identity can be encoded in the token.
11. Client sends its token together with some request.
12. Server check if the token is correctly signed and uses its information for authorization.

![Authorization communication](./auth.jpg)

This solution is however too complicated for this project as it requires use of an external authorization service which could be a project of its own.
gRPC has a built-in support for OAuth 2.0 which combined with TLS will give us everything that is actually required. 
For simplicity, the user is going to be authenticated using a basic password comparison and after authentication every operation is going to be allowed.

# Application design

## Client

Client is a simple command line application with five subcommands. On receiving responses the client prints logs on the screen or prints relevant information on the screen.

## Server

Server is an asynchronous application with a gRPC server, authorization system, several message handlers and three collections:

- Running processes
- Information about finished processes (removed on calling the `Stop` endpoint to free resources)
- Connected clients reading logs

![Teleport server](./server.jpg)

In production the information about finished processes would be kept only for a period of time to avoid reaching resource limits and possibly would be saved to an external file or database to save RAM, but in this simple challenge only internal RAM-based collection are used and there is no limit.

### Resource Limits
  Users can spawn remotely multiple processes that would normally interfere with whatever the server is doing normally.
  To prevent that it is necessary to introduce some kind of resource usage limits.
  Linux already has a solid mechanism to achieve that: [cgroups](https://en.wikipedia.org/wiki/Cgroups).
  Control groups allow you to set limits of resource usage on a process or a group of processes.
  Resources include memory, CPU, networking and hard drive usage.
  For the sake of simplicity, this project assumes a hardcoded 20% of a single CPU usage and 10 MB of memory as the actual limits imposed on all spawned processes.

# Tests

No project is complete until it is tested an confirmed to work.
While this project is not intended for production use, the patterns of testing are intended to match those of production quality systems.
Two levels of testing are intended for this project:
- Unit tests - written in the Golang language and using [mockgen](https://github.com/uber-go/mock) mock generation tool from Uber to remove some of dependencies.
- API tests of the server. While unit tests do confirm that small components of the project work correctly, they are known not to find many kinds of issues.
  [ISTQB](https://www.istqb.org/) recommends combining unit tests with component integration tests - tests that make all parts of the application work together.
  A natural choice are API tests that trigger the server API by launching and managing actual processes.

Because of the requirement to manage multiple clients in parallel (multithreading), there is a significant potential for synchronization issues.
Luckily golang provides race detector that will be enabled during both kinds of tests.

There are several kinds of tests that would normally be implemented for such a system but are skipped because of limited time:
- Performance tests - check how many parallel requests the system can handle.
- Reliability - long running tests of the system under random load that look for random crashes and resource leaks.
- Usability - feedback from uses on ease of use.
- Code reviews - while scientifically proven to provide huge quality improvements, they require more people in the team to be performed.

# Build system

Golang comes with a default build system that works on multiple platforms.
However the project requires set of external tools for code generation.
To enable a reproducible build, a `Dockerfile` with a complete build environment will be provided.
The same docker can be also used to launch all implemented tests.

Finally the built application should be wrapped inside another docker image, typically `alpine` as it provides the smallest size and 
small number of installed applications minimizes number of possible vulnerabilities.

# Libraries and tools

Golang libraries:

- [golang gRPC](https://github.com/grpc/grpc-go) - code generators for gRPC.
- [go-arg](https://github.com/alexflint/go-arg) - great command line argument parser. 
- [cgroups](https://github.com/containerd/cgroups) - Golang interface for the Linux cgroups.

Tests:

- Built-in golang test framework
- [mockgen](https://github.com/uber-go/mock) - mock generator from Uber.
- [testify](https://github.com/stretchr/testify) - popular golang library with assertions for unit tests.

Dockers:
- [golang](https://hub.docker.com/_/golang) - official golang docker, a solid base for building golang applications.
- [alpine](https://hub.docker.com/_/alpine) - minimalistic Linux, perfect for releasing services in the cloud.